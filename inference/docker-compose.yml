version: '3.8'

services:
  inference-pipeline:
    build: .
    container_name: anvl-inference-pipeline
    ports:
      - "8082:8082"
    environment:
      - PORT=8082
      - VEHICLE_DETECTION_MODEL=./models/yolov8_vehicle.pt
      - LICENSE_PLATE_DETECTION_MODEL=./models/plate_detector.pt
      - OCR_MODEL=./models/ocr_model
      - VEHICLE_ATTRIBUTES_MODEL=./models/vehicle_attributes.pt
      - VEHICLE_DETECTION_THRESHOLD=0.5
      - LICENSE_PLATE_THRESHOLD=0.7
      - OCR_THRESHOLD=0.8
      - VEHICLE_ATTRIBUTES_THRESHOLD=0.8
      - LOG_FILE=/var/log/anvil/inference.log
      - USE_GPU=true
      - GPU_DEVICE=0
      - MAX_CONCURRENT_REQUESTS=10
      - REQUEST_TIMEOUT=30000
    volumes:
      - ./logs:/var/log/anvil
      - ./models:/app/models
    networks:
      - anvl-network
    restart: unless-stopped

networks:
  anvl-network:
    driver: bridge